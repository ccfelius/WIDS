{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abdf7ba1",
   "metadata": {},
   "source": [
    "## XGBoost + LGBM Ensemble by both building and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b10cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from evaluation import RMSE\n",
    "from evaluation import helper_func\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgbm\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cd677",
   "metadata": {},
   "source": [
    "#### Preparing and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568b403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/train.csv\")\n",
    "submission = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1c49c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9705"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce249c5",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc11e71",
   "metadata": {},
   "source": [
    "#### delete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b22068",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/train.csv\")\n",
    "\n",
    "# to_delete = [\"days_with_fog\", \"direction_peak_wind_speed\", \"direction_max_wind_speed\", \"max_wind_speed\",\n",
    "#              \"days_above_90F\", \"days_above_110F\", \"Year_Factor\"]\n",
    "\n",
    "to_delete_less = [\"days_with_fog\", \"direction_peak_wind_speed\", \"direction_max_wind_speed\", \"max_wind_speed\"]\n",
    "# to_delete_less = [\"building_class\"]\n",
    "\n",
    "def delete_cols(dataframe, columns):\n",
    "    for colname in columns:\n",
    "        del dataframe[colname]\n",
    "\n",
    "delete_cols(reduced, to_delete_less)\n",
    "delete_cols(submission, to_delete_less)\n",
    "\n",
    "# # collect garbage\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dcc4b",
   "metadata": {},
   "source": [
    "#### Temperature difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10863790",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temp = [string for string in reduced.columns if 'min_temp' in string]\n",
    "max_temp = [string for string in reduced.columns if 'max_temp' in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30846537",
   "metadata": {},
   "outputs": [],
   "source": [
    "below_ex = [string for string in reduced.columns if 'days_below_30F' in string]\n",
    "above_ex = [string for string in reduced.columns if 'days_above_80F' in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e678928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Per month, do max - min\n",
    "\n",
    "for min_, max_ in zip(min_temp, max_temp):\n",
    "    name = min_.split(\"min\")[0] + \"diff\"\n",
    "    reduced[name] = reduced[max_] - reduced[min_]\n",
    "    \n",
    "for min_, max_ in zip(min_temp, max_temp):\n",
    "    name = min_.split(\"min\")[0] + \"diff\"\n",
    "    submission[name] = submission[max_] - submission[min_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e47cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_below_10f, days above_100f\n",
    "\n",
    "for min_, max_ in zip(below_ex, above_ex):\n",
    "    name = \"extreme_temp\"\n",
    "    reduced[name] = reduced[max_] - reduced[min_]\n",
    "    \n",
    "for min_, max_ in zip(below_ex, above_ex):\n",
    "    name = \"extreme_temp\"\n",
    "    submission[name] = submission[max_] - submission[min_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53cac5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp diff aug - january\n",
    "\n",
    "# reduced[\"climate\"] = (reduced[\"august_avg_temp\"] - reduced[\"january_avg_temp\"]) * reduced[['january_diff', 'february_diff',\n",
    "#                                                                                            'march_diff', 'april_diff', 'may_diff', 'june_diff',\n",
    "#                                                                                           'july_diff', 'august_diff', 'september_diff',\n",
    "#                                                                                           'october_diff', 'november_diff', 'december_diff']].mean(axis=1)\n",
    "\n",
    "\n",
    "# submission[\"climate\"] = (submission[\"august_avg_temp\"] - submission[\"january_avg_temp\"]) * submission[['january_diff', 'february_diff',\n",
    "#                                                                                            'march_diff', 'april_diff', 'may_diff', 'june_diff',\n",
    "#                                                                                           'july_diff', 'august_diff', 'september_diff',\n",
    "#                                                                                           'october_diff', 'november_diff', 'december_diff']].mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798f6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_cols(reduced, min_temp)\n",
    "# delete_cols(reduced, max_temp)\n",
    "# delete_cols(submission, min_temp)\n",
    "# delete_cols(submission, max_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a60d49",
   "metadata": {},
   "source": [
    "#### Impute variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a11098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take average per facility type for star_rating\n",
    "\n",
    "# red = reduced.groupby(\"facility_type\").mean()[\"energy_star_rating\"]\n",
    "# sub = submission.groupby(\"facility_type\").mean()[\"energy_star_rating\"]\n",
    "\n",
    "# fill_dict = {}\n",
    "\n",
    "# for i, j in zip(red.items(), sub.items()): \n",
    "#     avg = (i[1] + j[1]) / 2\n",
    "#     if math.isnan(avg) == False:\n",
    "#         fill_dict[i[0]] = avg\n",
    "    \n",
    "# nans = []\n",
    "\n",
    "# for i, j in zip(red.items(), sub.items()): \n",
    "#     avg = (i[1] + j[1]) / 2\n",
    "#     if math.isnan(avg) == False:\n",
    "#             continue\n",
    "#     nans.append(i[0])\n",
    "\n",
    "# for key in nans:\n",
    "#     fill_dict[key] = 10\n",
    "    \n",
    "# for i,j in reduced[reduced['energy_star_rating'].isna()][\"facility_type\"].items():\n",
    "#     reduced.loc[i,'energy_star_rating'] = fill_dict[j]\n",
    "    \n",
    "# for i,j in submission[submission['energy_star_rating'].isna()][\"facility_type\"].items():\n",
    "#     submission.loc[i,'energy_star_rating'] = fill_dict[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77abbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with mean, ensures highest correlation\n",
    "\n",
    "reduced['energy_star_rating'] = reduced['energy_star_rating'].fillna(56.0)\n",
    "submission['energy_star_rating'] = submission['energy_star_rating'].fillna(56.0)\n",
    "reduced['year_built'] = reduced['year_built'].fillna(reduced['year_built'].median())\n",
    "submission['year_built'] = submission['year_built'].fillna(submission['year_built'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba7519",
   "metadata": {},
   "source": [
    "#### Replace 'State 6'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6066cd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "\n",
    "def calc_vec(state, dataset):\n",
    "    vec = []\n",
    "    \n",
    "    temp = dataset[dataset[\"State_Factor\"] == state]\n",
    "    \n",
    "    for t in alltemps:\n",
    "            vec.append(temp[t].mean())\n",
    "    \n",
    "    return np.asarray(vec)\n",
    "\n",
    "def euclidian_distance_extensive(original, vectors, dataset):\n",
    "    \n",
    "    minval = 999\n",
    "    name = \"Null\"\n",
    "    \n",
    "    for s in allstates:\n",
    "        temp = dataset[dataset[\"State_Factor\"] == s]\n",
    "        \n",
    "        orig = []\n",
    "        diff = []\n",
    "        \n",
    "        for t in alltemps:\n",
    "            orig.append(original[t].mean())\n",
    "            diff.append(temp[t].mean())\n",
    "\n",
    "        o = np.asarray(orig)\n",
    "        d = np.asarray(diff)\n",
    "\n",
    "        dist = np.linalg.norm(o-d)\n",
    "        print(f'{s} has value {dist}')\n",
    "        \n",
    "        if dist < minval:\n",
    "            minval = dist\n",
    "            name = s\n",
    "    \n",
    "    print()\n",
    "    print(f\"Final value: ({name, minval})\")\n",
    "    return (name, minval)\n",
    "\n",
    "def get_vector(row):\n",
    "    \n",
    "    vec = []\n",
    "    for col in alltemps:\n",
    "        vec.append(row[col])\n",
    "    \n",
    "    return np.asarray(vec)\n",
    "\n",
    "def get_distance(row, distances):\n",
    "    \n",
    "    min_dist = 999\n",
    "    state = \"Null\"\n",
    "    \n",
    "    vec = get_vector(row)\n",
    "\n",
    "    for key, value in distances.items():\n",
    "        \n",
    "        dist = np.linalg.norm(value-vec)\n",
    "        \n",
    "#         print(f\"LOG: DIST={dist}, STATE={key}\")\n",
    "        \n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            state = key\n",
    "        \n",
    "#     print(f\"LOG: MIN_DIST={min_dist}, STATE={state}\")\n",
    "    return min_dist, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13eaeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state6 = reduced[reduced[\"State_Factor\"] == \"State_6\"]\n",
    "ids = []\n",
    "keys = []\n",
    "alltemps = [string for string in data.columns if 'temp' in string]\n",
    "allstates = list(reduced[\"State_Factor\"].unique())\n",
    "del allstates[3]\n",
    "\n",
    "state_values = dict()\n",
    "\n",
    "for i in allstates:\n",
    "    state_values[i] = calc_vec(i, data)\n",
    "\n",
    "for i in range(len(state6)):\n",
    "    row = state6.iloc[i]\n",
    "    ids.append(row['id'])\n",
    "    dist, k = get_distance(row, state_values)\n",
    "    keys.append(k)\n",
    "    \n",
    "mergedf = pd.DataFrame()\n",
    "mergedf[\"id\"] = ids\n",
    "mergedf[\"second_state\"] = keys\n",
    "\n",
    "reduced = reduced.merge(mergedf, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7539abb",
   "metadata": {},
   "source": [
    "#### Onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4290aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot = [\"facility_type\", \"State_Factor\", \"building_class\"]\n",
    "onehot = [\"State_Factor\", \"building_class\"]\n",
    "\"building_class\"\n",
    "\n",
    "def onehotter(dataframe, to_onehot):\n",
    "    \n",
    "    for i in to_onehot:\n",
    "        ohe_df = pd.get_dummies(dataframe[i], prefix=i)\n",
    "\n",
    "        # concat with original data\n",
    "            \n",
    "        dataframe = pd.concat([dataframe, ohe_df], axis=1).drop([i], axis=1)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f16cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = onehotter(submission, onehot)\n",
    "reduced = onehotter(reduced, onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f4ef7",
   "metadata": {},
   "source": [
    "#### Group facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a48bf862",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_facility_ = [\"Mixed_Use_\", \"Commercial_\", \"Data_\", \"Education_\", \"Food_\", \"Health_\", \"Lodging_\", \"Warehouse_\",\n",
    "                   \"Service_\", \"Retail_\", \"Public_Assembly_\", \"Public_Safety_\", \"Office_\", \"_Unit_Building\"]\n",
    "\n",
    "# for name in groups_facility_:\n",
    "#     newname = name + \"new\"\n",
    "#     reduced[\"facility_type\"] = reduced.facility_typer\n",
    "#     reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]\n",
    "#     submission[\"facility_type\"] = submission.facility_type.str.replace(name, newname)\n",
    "#     submission[\"facility_type\"] = submission[\"facility_type\"].str.split('new').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "720ceed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups_facility_ = [\"Mixed_Use_\", \"Office_\",  \"Lodging_\", \"Service_\", \"Retail_\", \"Public_Safety_\", \n",
    "#                      \"_Unit_Building\"]\n",
    "\n",
    "# for name in groups_facility_:\n",
    "#     newname = name + \"new\"\n",
    "#     reduced[\"facility_type\"] = reduced.facility_type.str.replace(name, newname)\n",
    "#     reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]\n",
    "#     submission[\"facility_type\"] = submission.facility_type.str.replace(name, newname)\n",
    "#     submission[\"facility_type\"] = submission[\"facility_type\"].str.split('new').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d655350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns with this regex, replace value by one of the new names\n",
    "\n",
    "# for name in groups_facility_:\n",
    "#     newname = name + \"new\"\n",
    "#     reduced[\"facility_type\"] = reduced.facility_type.str.replace(name, newname)\n",
    "#     reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44cb4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also onehot encode\n",
    "\n",
    "onehot = [\"facility_type\"]\n",
    "reduced = onehotter(reduced, onehot)\n",
    "submission = onehotter(submission, onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b8531",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716e3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(original, predicted):\n",
    "    \n",
    "    aggregate = 0\n",
    "    \n",
    "    for orig, pred in zip(original, predicted):\n",
    "        aggregate += (orig - pred)**2\n",
    "    \n",
    "    RMSE_ = math.sqrt(1/len(original) * aggregate)\n",
    "        \n",
    "    print(f'RMSE: {RMSE_}')\n",
    "    \n",
    "    return RMSE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6dd21",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82d490d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STATE 4, 8 en 10 samenvoegen!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2000c8f8",
   "metadata": {},
   "source": [
    "#### Divide per state & building type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aed0c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model per state_factor\n",
    "# train model per building_type\n",
    "# train catboost per building_type!\n",
    "\n",
    "red_commercial = reduced[reduced['building_class_Commercial'] == 1]\n",
    "red_residential = reduced[reduced['building_class_Residential'] == 1]\n",
    "del red_commercial['building_class_Commercial']\n",
    "del red_residential['building_class_Residential']\n",
    "\n",
    "sub_commercial = submission[submission['building_class_Commercial'] == 1]\n",
    "sub_residential = submission[submission['building_class_Residential'] == 1]\n",
    "del sub_commercial['building_class_Commercial']\n",
    "del sub_residential['building_class_Residential']\n",
    "\n",
    "# reduced commercial\n",
    "r_com_sf1 = red_commercial[(red_commercial[\"State_Factor_State_1\"] == 1) | (red_commercial[\"State_Factor_State_11\"] == 1)]\n",
    "r_com_sf4 = red_commercial[(red_commercial[\"State_Factor_State_4\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_4\") \n",
    "                           | (red_commercial[\"State_Factor_State_8\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_8\")\n",
    "                           | (red_commercial[\"State_Factor_State_10\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_10\")]\n",
    "r_com_sf2 = red_commercial[(red_commercial[\"State_Factor_State_2\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_2\")]\n",
    "\n",
    "# submission commercial\n",
    "s_com_sf1 = sub_commercial[(sub_commercial[\"State_Factor_State_1\"] == 1) |\n",
    "                          (sub_commercial[\"State_Factor_State_11\"] == 1)]\n",
    "s_com_sf2 = sub_commercial[sub_commercial[\"State_Factor_State_2\"] == 1 ]\n",
    "s_com_sf4 = sub_commercial[(sub_commercial[\"State_Factor_State_4\"] == 1) | \n",
    "                           (sub_commercial[\"State_Factor_State_8\"] == 1) |\n",
    "                          (sub_commercial[\"State_Factor_State_10\"] == 1)]\n",
    "\n",
    "# reduced residential\n",
    "r_res_sf1 = red_residential[(red_residential[\"State_Factor_State_1\"] == 1) | (red_residential[\"State_Factor_State_11\"] == 1)]\n",
    "r_res_sf2 = red_residential[(red_residential[\"State_Factor_State_2\"] == 1) | (red_residential[\"second_state\"] ==  \"State_2\")]\n",
    "r_res_sf4 = red_residential[(red_residential[\"State_Factor_State_4\"] == 1) | (red_residential[\"second_state\"] ==  \"State_4\") \n",
    "                            | (red_residential[\"State_Factor_State_8\"] == 1) | (red_residential[\"second_state\"] ==  \"State_8\")\n",
    "                           | (red_residential[\"State_Factor_State_10\"] == 1) | (red_residential[\"second_state\"] ==  \"State_10\")]\n",
    "\n",
    "\n",
    "# submission residential\n",
    "s_res_sf1 = sub_residential[(sub_residential[\"State_Factor_State_1\"] == 1) |\n",
    "                           (sub_residential[\"State_Factor_State_11\"] == 1)]\n",
    "s_res_sf2 = sub_residential[sub_residential[\"State_Factor_State_2\"] == 1 ]\n",
    "s_res_sf4 = sub_residential[(sub_residential[\"State_Factor_State_4\"] == 1) |\n",
    "                           (sub_residential[\"State_Factor_State_10\"] == 1) |\n",
    "                            (sub_residential[\"State_Factor_State_8\"] == 1) ]\n",
    "\n",
    "# delete unnecessary columns\n",
    "\n",
    "r_com_sf1 = r_com_sf1[r_com_sf1.columns.drop(list(r_com_sf1.filter(regex='State_Factor_State_')))]\n",
    "r_com_sf2 = r_com_sf2[r_com_sf2.columns.drop(list(r_com_sf2.filter(regex='State_Factor_State_')))]\n",
    "r_com_sf4 = r_com_sf4[r_com_sf4.columns.drop(list(r_com_sf4.filter(regex='State_Factor_State_')))]\n",
    "r_res_sf1 = r_res_sf1[r_res_sf1.columns.drop(list(r_res_sf1.filter(regex='State_Factor_State_')))]\n",
    "r_res_sf2 = r_res_sf2[r_res_sf2.columns.drop(list(r_res_sf2.filter(regex='State_Factor_State_')))]\n",
    "r_res_sf4 = r_res_sf4[r_res_sf4.columns.drop(list(r_res_sf4.filter(regex='State_Factor_State_')))]\n",
    "\n",
    "s_com_sf1 = s_com_sf1[s_com_sf1.columns.drop(list(s_com_sf1.filter(regex='State_Factor_State_')))]\n",
    "s_com_sf2 = s_com_sf2[s_com_sf2.columns.drop(list(s_com_sf2.filter(regex='State_Factor_State_')))]\n",
    "s_com_sf4 = s_com_sf4[s_com_sf4.columns.drop(list(s_com_sf4.filter(regex='State_Factor_State_')))]\n",
    "s_res_sf1 = s_res_sf1[s_res_sf1.columns.drop(list(s_res_sf1.filter(regex='State_Factor_State_')))]\n",
    "s_res_sf2 = s_res_sf2[s_res_sf2.columns.drop(list(s_res_sf2.filter(regex='State_Factor_State_')))]\n",
    "s_res_sf4 = s_res_sf4[s_res_sf4.columns.drop(list(s_res_sf4.filter(regex='State_Factor_State_')))]\n",
    "\n",
    "# weather etc is state specific? So maybe also different model for weather and then for the other factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee7a130",
   "metadata": {},
   "source": [
    "## Train and test data (not for submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "801006a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [r_com_sf1, r_com_sf2, r_com_sf4, r_res_sf1,\n",
    "           r_res_sf2, r_res_sf4]\n",
    "\n",
    "all_data_sub = [s_com_sf1, s_com_sf2, s_com_sf4, s_res_sf1,\n",
    "           s_res_sf2, s_res_sf4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3b242a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainall(all_data_):\n",
    "    \n",
    "    def get_pred(model_name):\n",
    "\n",
    "        X = model_name\n",
    "        ids = X[\"id\"]\n",
    "        X.pop(\"id\")\n",
    "\n",
    "        return X, ids\n",
    "\n",
    "    def get_X_y(model_name):\n",
    "\n",
    "        X = model_name\n",
    "        y = X['site_eui']\n",
    "        X.pop('site_eui')\n",
    "#         X.pop('id')\n",
    "#         X.pop('State_Factor_State_6')\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def runmodel_predict(X, y, testdata, model):\n",
    "        model.fit(X, y)\n",
    "        preds = model.predict(testdata)\n",
    "        return preds\n",
    "\n",
    "    def run_types_pred(trainset):\n",
    "\n",
    "        ids = []\n",
    "        true_y = []\n",
    "        resultlist_xgb = []\n",
    "        resultlist_lgbm = []\n",
    "        TEST_SIZE = 0.2\n",
    "\n",
    "        for j, t in enumerate(trainset):\n",
    "            \n",
    "            print(f\"SZ set = {len(t)}\")\n",
    "            \n",
    "            if len(t) < 2:\n",
    "                print(\"Skip\")\n",
    "                continue\n",
    "                \n",
    "            print(f\"Processing dataset {j+1}/{len(trainset)}\")\n",
    "\n",
    "            X, y = get_X_y(t)\n",
    "            X.pop(\"second_state\")\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=22)\n",
    "            X_train.pop(\"id\")\n",
    "            X_test, y_id = get_pred(X_test)\n",
    "            ids.append(y_id)\n",
    "            true_y.append(y_test)\n",
    "            \n",
    "            # XGBoost\n",
    "            print(\"XGBoost\")\n",
    "            X.pop(\"id\")\n",
    "            data_dmatrix = xgb.DMatrix(data = X, label = y)\n",
    "            model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                    max_depth = 11, alpha = 0.2, n_estimators = 1000)\n",
    "            \n",
    "            predicted = runmodel_predict(X_train, y_train, X_test, model)\n",
    "            resultlist_xgb.append(predicted)\n",
    "\n",
    "            # LightGBM\n",
    "            print(\"LightGBM\")\n",
    "            model = lgbm.LGBMRegressor(max_depth=10, learning_rate=0.2, n_estimators=2400)\n",
    "            predicted = runmodel_predict(X_train, y_train, X_test, model)\n",
    "            resultlist_lgbm.append(predicted)\n",
    "\n",
    "        return resultlist_xgb, resultlist_lgbm, ids, true_y\n",
    "    \n",
    "    return run_types_pred(all_data_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63c6dcb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SZ set = 8346\n",
      "Processing dataset 1/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "SZ set = 15942\n",
      "Processing dataset 2/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "SZ set = 7911\n",
      "Processing dataset 3/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "SZ set = 3684\n",
      "Processing dataset 4/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "SZ set = 31398\n",
      "Processing dataset 5/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "SZ set = 8476\n",
      "Processing dataset 6/6\n",
      "XGBoost\n",
      "LightGBM\n"
     ]
    }
   ],
   "source": [
    "xgb_res, lgbm_res, ids, y_true = trainall(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc75e075",
   "metadata": {},
   "source": [
    "#### Calculate RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea510fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_concat = [i for j in ids for i in j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76a0b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "original = [i for j in y_true for i in j]\n",
    "predicted_xgb = [item for sublist in xgb_res for item in sublist]\n",
    "predicted_lgbm = [item for sublist in lgbm_res for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c1866706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "RMSE: 37.614408479135236\n",
      "LightGBM\n",
      "RMSE: 39.08359835236008\n",
      "Average\n",
      "RMSE: 36.305090977739795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "36.305090977739795"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best result is 22.990013997679117\n",
    "\n",
    "print(\"XGBoost\")\n",
    "RMSE(original, predicted_xgb)\n",
    "\n",
    "print(\"LightGBM\")\n",
    "RMSE(original, predicted_lgbm)\n",
    "\n",
    "print(\"Average\")\n",
    "avg_predicted = []\n",
    "\n",
    "for i, j in zip(predicted_xgb, predicted_lgbm):\n",
    "    avg_predicted.append((i+j)/2)\n",
    "\n",
    "RMSE(original, avg_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "216a1b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-03b9be105f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wids",
   "language": "python",
   "name": "wids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
