{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abdf7ba1",
   "metadata": {},
   "source": [
    "## XGBoost + LGBM Ensemble by both building and state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b10cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from evaluation import RMSE\n",
    "from evaluation import helper_func\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import lightgbm as lgbm\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cd677",
   "metadata": {},
   "source": [
    "#### Preparing and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568b403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/train.csv\")\n",
    "submission = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1c49c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9705"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce249c5",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc11e71",
   "metadata": {},
   "source": [
    "#### delete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b22068",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/train.csv\")\n",
    "\n",
    "# to_delete = [\"days_with_fog\", \"direction_peak_wind_speed\", \"direction_max_wind_speed\", \"max_wind_speed\",\n",
    "#              \"days_above_90F\", \"days_above_110F\", \"Year_Factor\"]\n",
    "\n",
    "to_delete_less = [\"days_with_fog\", \"direction_peak_wind_speed\", \"direction_max_wind_speed\", \"max_wind_speed\"]\n",
    "# to_delete_less = [\"building_class\"]\n",
    "\n",
    "def delete_cols(dataframe, columns):\n",
    "    for colname in columns:\n",
    "        del dataframe[colname]\n",
    "\n",
    "delete_cols(reduced, to_delete_less)\n",
    "delete_cols(submission, to_delete_less)\n",
    "\n",
    "# # collect garbage\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dcc4b",
   "metadata": {},
   "source": [
    "#### Temperature difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10863790",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temp = [string for string in reduced.columns if 'min_temp' in string]\n",
    "max_temp = [string for string in reduced.columns if 'max_temp' in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30846537",
   "metadata": {},
   "outputs": [],
   "source": [
    "below_ex = [string for string in reduced.columns if 'days_below_30F' in string]\n",
    "above_ex = [string for string in reduced.columns if 'days_above_80F' in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e678928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Per month, do max - min\n",
    "\n",
    "for min_, max_ in zip(min_temp, max_temp):\n",
    "    name = min_.split(\"min\")[0] + \"diff\"\n",
    "    reduced[name] = reduced[max_] - reduced[min_]\n",
    "    \n",
    "for min_, max_ in zip(min_temp, max_temp):\n",
    "    name = min_.split(\"min\")[0] + \"diff\"\n",
    "    submission[name] = submission[max_] - submission[min_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1e47cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_below_10f, days above_100f\n",
    "\n",
    "for min_, max_ in zip(below_ex, above_ex):\n",
    "    name = \"extreme_temp\"\n",
    "    reduced[name] = reduced[max_] - reduced[min_]\n",
    "    \n",
    "for min_, max_ in zip(below_ex, above_ex):\n",
    "    name = \"extreme_temp\"\n",
    "    submission[name] = submission[max_] - submission[min_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53cac5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # temp diff aug - january\n",
    "\n",
    "# reduced[\"climate\"] = (reduced[\"august_avg_temp\"] - reduced[\"january_avg_temp\"]) * reduced[['january_diff', 'february_diff',\n",
    "#                                                                                            'march_diff', 'april_diff', 'may_diff', 'june_diff',\n",
    "#                                                                                           'july_diff', 'august_diff', 'september_diff',\n",
    "#                                                                                           'october_diff', 'november_diff', 'december_diff']].mean(axis=1)\n",
    "\n",
    "\n",
    "# submission[\"climate\"] = (submission[\"august_avg_temp\"] - submission[\"january_avg_temp\"]) * submission[['january_diff', 'february_diff',\n",
    "#                                                                                            'march_diff', 'april_diff', 'may_diff', 'june_diff',\n",
    "#                                                                                           'july_diff', 'august_diff', 'september_diff',\n",
    "#                                                                                           'october_diff', 'november_diff', 'december_diff']].mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "798f6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_cols(reduced, min_temp)\n",
    "# delete_cols(reduced, max_temp)\n",
    "# delete_cols(submission, min_temp)\n",
    "# delete_cols(submission, max_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a60d49",
   "metadata": {},
   "source": [
    "#### Impute variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a11098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take average per facility type for star_rating\n",
    "\n",
    "# red = reduced.groupby(\"facility_type\").mean()[\"energy_star_rating\"]\n",
    "# sub = submission.groupby(\"facility_type\").mean()[\"energy_star_rating\"]\n",
    "\n",
    "# fill_dict = {}\n",
    "\n",
    "# for i, j in zip(red.items(), sub.items()): \n",
    "#     avg = (i[1] + j[1]) / 2\n",
    "#     if math.isnan(avg) == False:\n",
    "#         fill_dict[i[0]] = avg\n",
    "    \n",
    "# nans = []\n",
    "\n",
    "# for i, j in zip(red.items(), sub.items()): \n",
    "#     avg = (i[1] + j[1]) / 2\n",
    "#     if math.isnan(avg) == False:\n",
    "#             continue\n",
    "#     nans.append(i[0])\n",
    "\n",
    "# for key in nans:\n",
    "#     fill_dict[key] = 10\n",
    "    \n",
    "# for i,j in reduced[reduced['energy_star_rating'].isna()][\"facility_type\"].items():\n",
    "#     reduced.loc[i,'energy_star_rating'] = fill_dict[j]\n",
    "    \n",
    "# for i,j in submission[submission['energy_star_rating'].isna()][\"facility_type\"].items():\n",
    "#     submission.loc[i,'energy_star_rating'] = fill_dict[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77abbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with mean, ensures highest correlation\n",
    "\n",
    "# reduced['energy_star_rating'] = reduced['energy_star_rating'].fillna(56.0)\n",
    "# submission['energy_star_rating'] = submission['energy_star_rating'].fillna(56.0)\n",
    "reduced['year_built'] = reduced['year_built'].fillna(reduced['year_built'].median())\n",
    "submission['year_built'] = submission['year_built'].fillna(submission['year_built'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba7519",
   "metadata": {},
   "source": [
    "#### deal with state 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7d1a5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "\n",
    "def calc_vec(state, dataset):\n",
    "    vec = []\n",
    "    \n",
    "    temp = dataset[dataset[\"State_Factor\"] == state]\n",
    "    \n",
    "    for t in alltemps:\n",
    "            vec.append(temp[t].mean())\n",
    "    \n",
    "    return np.asarray(vec)\n",
    "\n",
    "def euclidian_distance_extensive(original, vectors, dataset):\n",
    "    \n",
    "    minval = 999\n",
    "    name = \"Null\"\n",
    "    \n",
    "    for s in allstates:\n",
    "        temp = dataset[dataset[\"State_Factor\"] == s]\n",
    "        \n",
    "        orig = []\n",
    "        diff = []\n",
    "        \n",
    "        for t in alltemps:\n",
    "            orig.append(original[t].mean())\n",
    "            diff.append(temp[t].mean())\n",
    "\n",
    "        o = np.asarray(orig)\n",
    "        d = np.asarray(diff)\n",
    "\n",
    "        dist = np.linalg.norm(o-d)\n",
    "        print(f'{s} has value {dist}')\n",
    "        \n",
    "        if dist < minval:\n",
    "            minval = dist\n",
    "            name = s\n",
    "    \n",
    "    print()\n",
    "    print(f\"Final value: ({name, minval})\")\n",
    "    return (name, minval)\n",
    "\n",
    "def get_vector(row):\n",
    "    \n",
    "    vec = []\n",
    "    for col in alltemps:\n",
    "        vec.append(row[col])\n",
    "    \n",
    "    return np.asarray(vec)\n",
    "\n",
    "def get_distance(row, distances):\n",
    "    \n",
    "    min_dist = 999\n",
    "    state = \"Null\"\n",
    "    \n",
    "    vec = get_vector(row)\n",
    "\n",
    "    for key, value in distances.items():\n",
    "        \n",
    "        dist = np.linalg.norm(value-vec)\n",
    "        \n",
    "#         print(f\"LOG: DIST={dist}, STATE={key}\")\n",
    "        \n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            state = key\n",
    "        \n",
    "#     print(f\"LOG: MIN_DIST={min_dist}, STATE={state}\")\n",
    "    return min_dist, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dd5701d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state6 = reduced[reduced[\"State_Factor\"] == \"State_6\"]\n",
    "ids = []\n",
    "keys = []\n",
    "alltemps = [string for string in data.columns if 'temp' in string]\n",
    "allstates = list(reduced[\"State_Factor\"].unique())\n",
    "del allstates[3]\n",
    "\n",
    "state_values = dict()\n",
    "\n",
    "for i in allstates:\n",
    "    state_values[i] = calc_vec(i, data)\n",
    "\n",
    "for i in range(len(state6)):\n",
    "    row = state6.iloc[i]\n",
    "    ids.append(row['id'])\n",
    "    dist, k = get_distance(row, state_values)\n",
    "    keys.append(k)\n",
    "    \n",
    "mergedf = pd.DataFrame()\n",
    "mergedf[\"id\"] = ids\n",
    "mergedf[\"second_state\"] = keys\n",
    "\n",
    "reduced = reduced.merge(mergedf, how='left', on='id')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7539abb",
   "metadata": {},
   "source": [
    "#### Onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4290aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot = [\"facility_type\", \"State_Factor\", \"building_class\"]\n",
    "onehot = [\"State_Factor\", \"building_class\"]\n",
    "\"building_class\"\n",
    "\n",
    "def onehotter(dataframe, to_onehot):\n",
    "    \n",
    "    for i in to_onehot:\n",
    "        ohe_df = pd.get_dummies(dataframe[i], prefix=i)\n",
    "\n",
    "        # concat with original data\n",
    "            \n",
    "        dataframe = pd.concat([dataframe, ohe_df], axis=1).drop([i], axis=1)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f16cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = onehotter(submission, onehot)\n",
    "reduced = onehotter(reduced, onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f4ef7",
   "metadata": {},
   "source": [
    "#### Group facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a48bf862",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_facility_ = [\"Mixed_Use_\", \"Commercial_\", \"Data_\", \"Education_\", \"Food_\", \"Health_\", \"Lodging_\", \"Warehouse_\",\n",
    "                   \"Service_\", \"Retail_\", \"Public_Assembly_\", \"Public_Safety_\", \"Office_\", \"_Unit_Building\"]\n",
    "\n",
    "for name in groups_facility_:\n",
    "    newname = name + \"new\"\n",
    "    reduced[\"facility_type\"] = reduced.facility_type.str.replace(name, newname)\n",
    "    reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]\n",
    "    submission[\"facility_type\"] = submission.facility_type.str.replace(name, newname)\n",
    "    submission[\"facility_type\"] = submission[\"facility_type\"].str.split('new').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "720ceed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # groups_facility_ = [\"Mixed_Use_\", \"Office_\",  \"Lodging_\", \"Service_\", \"Retail_\", \"Public_Safety_\", \n",
    "# #                      \"_Unit_Building\"]\n",
    "\n",
    "# for name in groups_facility_:\n",
    "#     newname = name + \"new\"\n",
    "#     reduced[\"facility_type\"] = reduced.facility_type.str.replace(name, newname)\n",
    "#     reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]\n",
    "#     submission[\"facility_type\"] = submission.facility_type.str.replace(name, newname)\n",
    "#     submission[\"facility_type\"] = submission[\"facility_type\"].str.split('new').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d655350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns with this regex, replace value by one of the new names\n",
    "\n",
    "# for name in groups_facility_:\n",
    "#     newname = name + \"new\"\n",
    "#     reduced[\"facility_type\"] = reduced.facility_type.str.replace(name, newname)\n",
    "#     reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "44cb4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also onehot encode\n",
    "\n",
    "onehot = [\"facility_type\"]\n",
    "reduced = onehotter(reduced, onehot)\n",
    "submission = onehotter(submission, onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b8531",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "716e3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(original, predicted):\n",
    "    \n",
    "    aggregate = 0\n",
    "    \n",
    "    for orig, pred in zip(original, predicted):\n",
    "        aggregate += (orig - pred)**2\n",
    "    \n",
    "    RMSE_ = math.sqrt(1/len(original) * aggregate)\n",
    "        \n",
    "    print(f'RMSE: {RMSE_}')\n",
    "    \n",
    "    return RMSE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6dd21",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2000c8f8",
   "metadata": {},
   "source": [
    "#### Divide per state & building type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ac2f8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model per state_factor\n",
    "# train model per building_type\n",
    "# train catboost per building_type!\n",
    "\n",
    "red_commercial = reduced[reduced['building_class_Commercial'] == 1]\n",
    "red_residential = reduced[reduced['building_class_Residential'] == 1]\n",
    "del red_commercial['building_class_Commercial']\n",
    "del red_residential['building_class_Residential']\n",
    "\n",
    "sub_commercial = submission[submission['building_class_Commercial'] == 1]\n",
    "sub_residential = submission[submission['building_class_Residential'] == 1]\n",
    "del sub_commercial['building_class_Commercial']\n",
    "del sub_residential['building_class_Residential']\n",
    "\n",
    "# reduced commercial\n",
    "r_com_sf1 = red_commercial[(red_commercial[\"State_Factor_State_1\"] == 1) | (red_commercial[\"State_Factor_State_11\"] == 1)]\n",
    "r_com_sf4 = red_commercial[(red_commercial[\"State_Factor_State_4\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_4\") \n",
    "                           | (red_commercial[\"State_Factor_State_8\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_8\")\n",
    "                           | (red_commercial[\"State_Factor_State_10\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_10\")]\n",
    "r_com_sf2 = red_commercial[(red_commercial[\"State_Factor_State_2\"] == 1) | (red_commercial[\"second_state\"] ==  \"State_2\")]\n",
    "\n",
    "# submission commercial\n",
    "s_com_sf1 = sub_commercial[(sub_commercial[\"State_Factor_State_1\"] == 1) |\n",
    "                          (sub_commercial[\"State_Factor_State_11\"] == 1)]\n",
    "s_com_sf2 = sub_commercial[sub_commercial[\"State_Factor_State_2\"] == 1 ]\n",
    "s_com_sf4 = sub_commercial[(sub_commercial[\"State_Factor_State_4\"] == 1) | \n",
    "                           (sub_commercial[\"State_Factor_State_8\"] == 1) |\n",
    "                          (sub_commercial[\"State_Factor_State_10\"] == 1)]\n",
    "\n",
    "# reduced residential\n",
    "r_res_sf1 = red_residential[(red_residential[\"State_Factor_State_1\"] == 1) | (red_residential[\"State_Factor_State_11\"] == 1)]\n",
    "r_res_sf2 = red_residential[(red_residential[\"State_Factor_State_2\"] == 1) | (red_residential[\"second_state\"] ==  \"State_2\")]\n",
    "r_res_sf4 = red_residential[(red_residential[\"State_Factor_State_4\"] == 1) | (red_residential[\"second_state\"] ==  \"State_4\") \n",
    "                            | (red_residential[\"State_Factor_State_8\"] == 1) | (red_residential[\"second_state\"] ==  \"State_8\")\n",
    "                           | (red_residential[\"State_Factor_State_10\"] == 1) | (red_residential[\"second_state\"] ==  \"State_10\")]\n",
    "\n",
    "\n",
    "# submission residential\n",
    "s_res_sf1 = sub_residential[(sub_residential[\"State_Factor_State_1\"] == 1) |\n",
    "                           (sub_residential[\"State_Factor_State_11\"] == 1)]\n",
    "s_res_sf2 = sub_residential[sub_residential[\"State_Factor_State_2\"] == 1 ]\n",
    "s_res_sf4 = sub_residential[(sub_residential[\"State_Factor_State_4\"] == 1) |\n",
    "                           (sub_residential[\"State_Factor_State_10\"] == 1) |\n",
    "                            (sub_residential[\"State_Factor_State_8\"] == 1) ]\n",
    "\n",
    "# delete unnecessary columns\n",
    "\n",
    "r_com_sf1 = r_com_sf1[r_com_sf1.columns.drop(list(r_com_sf1.filter(regex='State_Factor_State_')))]\n",
    "r_com_sf2 = r_com_sf2[r_com_sf2.columns.drop(list(r_com_sf2.filter(regex='State_Factor_State_')))]\n",
    "r_com_sf4 = r_com_sf4[r_com_sf4.columns.drop(list(r_com_sf4.filter(regex='State_Factor_State_')))]\n",
    "r_res_sf1 = r_res_sf1[r_res_sf1.columns.drop(list(r_res_sf1.filter(regex='State_Factor_State_')))]\n",
    "r_res_sf2 = r_res_sf2[r_res_sf2.columns.drop(list(r_res_sf2.filter(regex='State_Factor_State_')))]\n",
    "r_res_sf4 = r_res_sf4[r_res_sf4.columns.drop(list(r_res_sf4.filter(regex='State_Factor_State_')))]\n",
    "\n",
    "s_com_sf1 = s_com_sf1[s_com_sf1.columns.drop(list(s_com_sf1.filter(regex='State_Factor_State_')))]\n",
    "s_com_sf2 = s_com_sf2[s_com_sf2.columns.drop(list(s_com_sf2.filter(regex='State_Factor_State_')))]\n",
    "s_com_sf4 = s_com_sf4[s_com_sf4.columns.drop(list(s_com_sf4.filter(regex='State_Factor_State_')))]\n",
    "s_res_sf1 = s_res_sf1[s_res_sf1.columns.drop(list(s_res_sf1.filter(regex='State_Factor_State_')))]\n",
    "s_res_sf2 = s_res_sf2[s_res_sf2.columns.drop(list(s_res_sf2.filter(regex='State_Factor_State_')))]\n",
    "s_res_sf4 = s_res_sf4[s_res_sf4.columns.drop(list(s_res_sf4.filter(regex='State_Factor_State_')))]\n",
    "\n",
    "# weather etc is state specific? So maybe also different model for weather and then for the other factors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f97e88b",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88dabf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = [r_com_sf1, r_com_sf2, r_com_sf4, r_res_sf1,\n",
    "           r_res_sf2, r_res_sf4]\n",
    "\n",
    "all_data_sub = [s_com_sf1, s_com_sf2, s_com_sf4, s_res_sf1,\n",
    "           s_res_sf2, s_res_sf4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "33ad7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit(data_train, data_test):\n",
    "    \n",
    "    def get_pred(model_name):\n",
    "\n",
    "        X = model_name\n",
    "        ids = X[\"id\"]\n",
    "        X.pop(\"id\")\n",
    "\n",
    "        return X, ids\n",
    "\n",
    "    def get_X_y(model_name):\n",
    "\n",
    "        X = model_name\n",
    "        y = X['site_eui']\n",
    "        y_id = X['id']\n",
    "        X.pop('site_eui')\n",
    "        X.pop('id')\n",
    "\n",
    "        return X, y, y_id\n",
    "\n",
    "    def runmodel_predict(X, y, testdata, model):\n",
    "        model.fit(X, y)\n",
    "        preds = model.predict(testdata)\n",
    "        return preds\n",
    "\n",
    "    def run_types_pred(data_train, data_test):\n",
    "\n",
    "        ids = []\n",
    "        resultlist_xgb = []\n",
    "        resultlist_lgbm = []\n",
    "        counter = 0\n",
    "\n",
    "        for train, test in zip(data_train, data_test):\n",
    "            counter += 1\n",
    "            \n",
    "            print(f\"Training model {counter}/{len(data_train)}\")\n",
    "            \n",
    "            if (len(train) < 2) | (len(test) == 0):\n",
    "                print(f\"WARNING: Empty training or test set, skipping {len(test)} values\")\n",
    "                continue\n",
    "                \n",
    "                \n",
    "            X, y, y_idx = get_X_y(train)\n",
    "            X.pop(\"second_state\")\n",
    "            testdata, y_id = get_pred(test)\n",
    "            ids.append(y_id)\n",
    "            \n",
    "            # XGBoost\n",
    "            print(\"XGBoost\")\n",
    "            data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "            model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                    max_depth = 11, alpha = 0.2, n_estimators = 1000)\n",
    "\n",
    "            predicted = runmodel_predict(X, y, testdata, model)\n",
    "            resultlist_xgb.append(predicted)\n",
    "\n",
    "            # LightGBM\n",
    "\n",
    "            print(\"LightGBM\")\n",
    "            model = lgbm.LGBMRegressor(max_depth=10, learning_rate=0.2, n_estimators=2600)\n",
    "            predicted = runmodel_predict(X, y, testdata, model)\n",
    "            resultlist_lgbm.append(predicted)\n",
    "\n",
    "        return resultlist_xgb, resultlist_lgbm, ids\n",
    "    \n",
    "    return run_types_pred(data_train, data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "551a9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "Training model 2/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "Training model 3/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "Training model 4/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "Training model 5/6\n",
      "XGBoost\n",
      "LightGBM\n",
      "Training model 6/6\n",
      "XGBoost\n",
      "LightGBM\n"
     ]
    }
   ],
   "source": [
    "to_concat_xgb_t, to_concat_lgbm_t, ids = submit(all_data, all_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bf86bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2 = [i for si in ids for i in si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6d536b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids2 heeft id's\n",
    "\n",
    "ids2 = [i for si in ids for i in si]\n",
    "xgb = []\n",
    "lgbm = []\n",
    "\n",
    "for i in to_concat_xgb_t:\n",
    "    xgb.append(i)\n",
    "    \n",
    "for i in to_concat_lgbm_t:\n",
    "    lgbm.append(i)\n",
    "    \n",
    "\n",
    "xgb = [item for sublist in xgb for item in sublist]\n",
    "lgbm = [item for sublist in lgbm for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8d0fc55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9705, 9705, 9705)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xgb), len(lgbm), len(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0756af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_predicted = []\n",
    "\n",
    "for i, j in zip(xgb, lgbm):\n",
    "    avg_predicted.append((i*2+j)/3)\n",
    "    \n",
    "avg_predicted2 = []\n",
    "\n",
    "for i, j in zip(xgb, lgbm):\n",
    "    avg_predicted2.append((i+j)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac3fc0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197.58763, 236.48914, 176.75452, 232.97636, 231.80457]\n",
      "[177.48198458941116, 174.81983297888357, 185.42676994637088, 219.8602316857091, 195.07377835096472]\n",
      "[190.88574901352766, 215.93270148775287, 179.64526771649864, 228.60431998573117, 219.56096973677992]\n",
      "[187.53480790749853, 205.65448436053555, 181.0906432739667, 226.41829791072564, 213.43917189032612]\n",
      "[75757, 75758, 75759, 75760, 75761]\n"
     ]
    }
   ],
   "source": [
    "print(xgb[:5])\n",
    "print(lgbm[:5])\n",
    "print(avg_predicted[:5])\n",
    "print(avg_predicted2[:5])\n",
    "print(ids2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4d0abc61",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-03b9be105f74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6c2d0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site_eui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75757</td>\n",
       "      <td>187.534808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75758</td>\n",
       "      <td>205.654484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75759</td>\n",
       "      <td>181.090643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75760</td>\n",
       "      <td>226.418298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75761</td>\n",
       "      <td>213.439172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    site_eui\n",
       "0  75757  187.534808\n",
       "1  75758  205.654484\n",
       "2  75759  181.090643\n",
       "3  75760  226.418298\n",
       "4  75761  213.439172"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result2 = pd.DataFrame()\n",
    "result2[\"id\"] = ids2\n",
    "result2[\"site_eui\"] = avg_predicted2\n",
    "result2 = result2.sort_values(by=['id'])\n",
    "result2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "49530bfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site_eui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75757</td>\n",
       "      <td>190.885749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75758</td>\n",
       "      <td>215.932701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75759</td>\n",
       "      <td>179.645268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75760</td>\n",
       "      <td>228.604320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75761</td>\n",
       "      <td>219.560970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    site_eui\n",
       "0  75757  190.885749\n",
       "1  75758  215.932701\n",
       "2  75759  179.645268\n",
       "3  75760  228.604320\n",
       "4  75761  219.560970"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame()\n",
    "result[\"id\"] = ids2\n",
    "result[\"site_eui\"] = avg_predicted\n",
    "result = result.sort_values(by=['id'])\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ccd82ccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site_eui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75757</td>\n",
       "      <td>197.587631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75758</td>\n",
       "      <td>236.489136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75759</td>\n",
       "      <td>176.754517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75760</td>\n",
       "      <td>232.976364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75761</td>\n",
       "      <td>231.804565</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    site_eui\n",
       "0  75757  197.587631\n",
       "1  75758  236.489136\n",
       "2  75759  176.754517\n",
       "3  75760  232.976364\n",
       "4  75761  231.804565"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_xgb = pd.DataFrame()\n",
    "result_xgb[\"id\"] = ids2\n",
    "result_xgb[\"site_eui\"] = xgb\n",
    "result_xgb = result_xgb.sort_values(by=['id'])\n",
    "result_xgb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "890812d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>site_eui</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75757</td>\n",
       "      <td>177.481985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>75758</td>\n",
       "      <td>174.819833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75759</td>\n",
       "      <td>185.426770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75760</td>\n",
       "      <td>219.860232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75761</td>\n",
       "      <td>195.073778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    site_eui\n",
       "0  75757  177.481985\n",
       "1  75758  174.819833\n",
       "2  75759  185.426770\n",
       "3  75760  219.860232\n",
       "4  75761  195.073778"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_lgbm = pd.DataFrame()\n",
    "result_lgbm[\"id\"] = ids2\n",
    "result_lgbm[\"site_eui\"] = lgbm\n",
    "result_lgbm = result_lgbm.sort_values(by=['id'])\n",
    "result_lgbm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b56129f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm_state_build_mix1.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89add972",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm_state_build_mix1.csv', index=False, header=True)result_lgbm.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm_state_build_lgbm2.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2ac42b",
   "metadata": {},
   "source": [
    "#### Write to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d9c76257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV file\n",
    "\n",
    "result.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm_state_build_mix1111.csv', index=False, header=True)\n",
    "result2.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm_state_build_mix2222.csv', index=False, header=True)\n",
    "result_xgb.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm_state_build_xgb222.csv', index=False, header=True)\n",
    "result_lgbm.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm_state_build_lgbm222.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a5e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wids",
   "language": "python",
   "name": "wids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
