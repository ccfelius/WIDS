{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abdf7ba1",
   "metadata": {},
   "source": [
    "## Sample Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65a41f3",
   "metadata": {},
   "source": [
    "Based on the exploration, we try the following *as a starting point*.\n",
    "\n",
    "> #### Delete the following columns\n",
    "> - days_with_fog\n",
    "> - direction_peak_wind_speed\n",
    "> - direction_max_wind_speed\n",
    "> - max_wind_speed\n",
    "> - year_built\n",
    "> - days_above_90F\n",
    "> - days_above_110F\n",
    "> - facility_type\n",
    "> - site_eui (obviously, because target column)\n",
    "> - For now also delete Year_Factor\n",
    "\n",
    "> #### Impute missing values for energy_star_rating \n",
    "> Imputing is done by replacing nan by the mean <br>\n",
    "> By second thoughts we do NOT impute as XGBoost infers missing values\n",
    "\n",
    "> #### One-hot encode categorical values \n",
    "> - State_Factor\n",
    "> - Building_Class\n",
    "\n",
    "For the sample model, we use **random forest** and **xgboost**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83b10cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from evaluation import RMSE\n",
    "from evaluation import helper_func\n",
    "import pandas as pd\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from catboost import CatBoostRegressor\n",
    "import lightgbm as lgbm\n",
    "import time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import KFold\n",
    "import optuna\n",
    "import math\n",
    "from sklearn.model_selection import cross_val_score, KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21cd677",
   "metadata": {},
   "source": [
    "#### Preparing and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568b403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/train.csv\")\n",
    "submission = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad1c49c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9705"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce249c5",
   "metadata": {},
   "source": [
    "### Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc11e71",
   "metadata": {},
   "source": [
    "#### delete columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8b22068",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/train.csv\")\n",
    "\n",
    "# to_delete = [\"days_with_fog\", \"direction_peak_wind_speed\", \"direction_max_wind_speed\", \"max_wind_speed\",\n",
    "#              \"days_above_90F\", \"days_above_110F\", \"Year_Factor\"]\n",
    "\n",
    "to_delete_less = [\"days_with_fog\", \"direction_peak_wind_speed\", \"direction_max_wind_speed\", \"max_wind_speed\"]\n",
    "# to_delete_less = [\"building_class\"]\n",
    "\n",
    "def delete_cols(dataframe, columns):\n",
    "    for colname in columns:\n",
    "        del dataframe[colname]\n",
    "\n",
    "delete_cols(reduced, to_delete_less)\n",
    "delete_cols(submission, to_delete_less)\n",
    "\n",
    "# # collect garbage\n",
    "# gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6dcc4b",
   "metadata": {},
   "source": [
    "#### Temperature difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10863790",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_temp = [string for string in reduced.columns if 'min_temp' in string]\n",
    "max_temp = [string for string in reduced.columns if 'max_temp' in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30846537",
   "metadata": {},
   "outputs": [],
   "source": [
    "below_ex = [string for string in reduced.columns if 'days_below_30F' in string]\n",
    "above_ex = [string for string in reduced.columns if 'days_above_80F' in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8df4eeb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['days_above_80F']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "above_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e678928d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per month, do max - min\n",
    "\n",
    "for min_, max_ in zip(min_temp, max_temp):\n",
    "    name = min_.split(\"min\")[0] + \"diff\"\n",
    "    reduced[name] = reduced[max_] - reduced[min_]\n",
    "    \n",
    "for min_, max_ in zip(min_temp, max_temp):\n",
    "    name = min_.split(\"min\")[0] + \"diff\"\n",
    "    submission[name] = submission[max_] - submission[min_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1e47cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# days_below_10f, days above_100f\n",
    "\n",
    "for min_, max_ in zip(below_ex, above_ex):\n",
    "    name = \"extreme_temp\"\n",
    "    reduced[name] = reduced[max_] - reduced[min_]\n",
    "    \n",
    "for min_, max_ in zip(below_ex, above_ex):\n",
    "    name = \"extreme_temp\"\n",
    "    submission[name] = submission[max_] - submission[min_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53cac5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp diff aug - january\n",
    "\n",
    "# reduced[\"climate\"] = (reduced[\"august_avg_temp\"] - reduced[\"january_avg_temp\"]) * reduced[['january_diff', 'february_diff',\n",
    "#                                                                                            'march_diff', 'april_diff', 'may_diff', 'june_diff',\n",
    "#                                                                                           'july_diff', 'august_diff', 'september_diff',\n",
    "#                                                                                           'october_diff', 'november_diff', 'december_diff']].mean(axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fafef0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in reduced.columns:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "798f6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete_cols(reduced, min_temp)\n",
    "# delete_cols(reduced, max_temp)\n",
    "# delete_cols(submission, min_temp)\n",
    "# delete_cols(submission, max_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a60d49",
   "metadata": {},
   "source": [
    "#### Impute variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a11098d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take average per facility type for star_rating\n",
    "\n",
    "# red = reduced.groupby(\"facility_type\").mean()[\"energy_star_rating\"]\n",
    "# sub = submission.groupby(\"facility_type\").mean()[\"energy_star_rating\"]\n",
    "\n",
    "# fill_dict = {}\n",
    "\n",
    "# for i, j in zip(red.items(), sub.items()): \n",
    "#     avg = (i[1] + j[1]) / 2\n",
    "#     if math.isnan(avg) == False:\n",
    "#         fill_dict[i[0]] = avg\n",
    "    \n",
    "# nans = []\n",
    "\n",
    "# for i, j in zip(red.items(), sub.items()): \n",
    "#     avg = (i[1] + j[1]) / 2\n",
    "#     if math.isnan(avg) == False:\n",
    "#             continue\n",
    "#     nans.append(i[0])\n",
    "\n",
    "# for key in nans:\n",
    "#     fill_dict[key] = 10\n",
    "    \n",
    "# for i,j in reduced[reduced['energy_star_rating'].isna()][\"facility_type\"].items():\n",
    "#     reduced.loc[i,'energy_star_rating'] = fill_dict[j]\n",
    "    \n",
    "# for i,j in submission[submission['energy_star_rating'].isna()][\"facility_type\"].items():\n",
    "#     submission.loc[i,'energy_star_rating'] = fill_dict[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a77abbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute with mean, ensures highest correlation\n",
    "\n",
    "reduced['energy_star_rating'] = reduced['energy_star_rating'].fillna(56.0)\n",
    "submission['energy_star_rating'] = submission['energy_star_rating'].fillna(56.0)\n",
    "# median 76.0 no\n",
    "# 63 random\n",
    "# 56 works best\n",
    "reduced['year_built'] = reduced['year_built'].fillna(reduced['year_built'].median())\n",
    "submission['year_built'] = submission['year_built'].fillna(submission['year_built'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "049925d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fillmedian = [\"direction_max_wind_speed\", \"direction_peak_wind_speed\", \"days_with_fog\", \"max_wind_speed\"]\n",
    "\n",
    "# for i in fillmedian:\n",
    "#     reduced[i] = reduced[i].fillna(reduced[i].median())\n",
    "#     submission[i] = submission[i].fillna(submission[i].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "160005d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test which value enhances highest correlation still\n",
    "# highest_corr = []\n",
    "\n",
    "# for i in data['energy_star_rating'].unique():\n",
    "#     d = pd.read_csv(\"/Users/charlottefelius/documents/wids2022/WIDS/data/train.csv\")\n",
    "#     d['energy_star_rating'] = d['energy_star_rating'].fillna(i)\n",
    "#     correlations = helper_func.get_correlation(d, 'site_eui', 0)[1]\n",
    "#     highest_corr.append((i, correlations[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ba7519",
   "metadata": {},
   "source": [
    "#### Create new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "45bf504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below compute sum of below 30 and sum of above 80\n",
    "# days_ = [string for string in reduced.columns if 'days_' in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52aa2db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # below compute sum of below 30 and sum of above 80\n",
    "# reduced['d_below_30_F'] = reduced[list(reduced.filter(regex='days_below_'))].sum(axis=1)\n",
    "# reduced['d_above_80_F'] = reduced[list(reduced.filter(regex='days_above_'))].sum(axis=1)\n",
    "# submission['d_below_30_F'] = submission[list(submission.filter(regex='days_below_'))].sum(axis=1)\n",
    "# submission['d_above_80_F'] = submission[list(submission.filter(regex='days_above_'))].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14c1c645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the other columns\n",
    "# delete_cols(reduced, days_)\n",
    "# delete_cols(submission, days_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7539abb",
   "metadata": {},
   "source": [
    "#### Onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4290aca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# onehot = [\"facility_type\", \"State_Factor\", \"building_class\"]\n",
    "onehot = [\"State_Factor\", \"building_class\"]\n",
    "#\"building_class\"\n",
    "\n",
    "def onehotter(dataframe, to_onehot):\n",
    "    \n",
    "    for i in to_onehot:\n",
    "        ohe_df = pd.get_dummies(dataframe[i], prefix=i)\n",
    "\n",
    "        # concat with original data\n",
    "            \n",
    "        dataframe = pd.concat([dataframe, ohe_df], axis=1).drop([i], axis=1)\n",
    "        \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f16cda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = onehotter(submission, onehot)\n",
    "reduced = onehotter(reduced, onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6f4ef7",
   "metadata": {},
   "source": [
    "#### Group facility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a48bf862",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups_facility_ = [\"Mixed_Use_\", \"Commercial_\", \"Data_\", \"Education_\", \"Food_\", \"Health_\", \"Lodging_\", \"Warehouse_\",\n",
    "                   \"Service_\", \"Retail_\", \"Public_Assembly_\", \"Public_Safety_\", \"Office_\", \"_Unit_Building\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "720ceed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# groups_facility_ = [\"Mixed_Use_\", \"Office_\",  \"Lodging_\", \"Service_\", \"Retail_\", \"Public_Safety_\", \n",
    "#                      \"_Unit_Building\"]\n",
    "\n",
    "for name in groups_facility_:\n",
    "    newname = name + \"new\"\n",
    "    reduced[\"facility_type\"] = reduced.facility_type.str.replace(name, newname)\n",
    "    reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]\n",
    "    submission[\"facility_type\"] = submission.facility_type.str.replace(name, newname)\n",
    "    submission[\"facility_type\"] = submission[\"facility_type\"].str.split('new').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d655350b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all columns with this regex, replace value by one of the new names\n",
    "\n",
    "# for name in groups_facility_:\n",
    "#     newname = name + \"new\"\n",
    "#     reduced[\"facility_type\"] = reduced.facility_type.str.replace(name, newname)\n",
    "#     reduced[\"facility_type\"] = reduced[\"facility_type\"].str.split('new').str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44cb4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also onehot encode\n",
    "\n",
    "onehot = [\"facility_type\"]\n",
    "reduced = onehotter(reduced, onehot)\n",
    "submission = onehotter(submission, onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f729a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model per state_factor\n",
    "# train model per building_type\n",
    "# train catboost per building_type!\n",
    "\n",
    "# red_commercial = reduced[reduced['building_class_Commercial'] == 1]\n",
    "# red_residential = reduced[reduced['building_class_Residential'] == 1]\n",
    "# del red_commercial['building_class_Commercial']\n",
    "# del red_residential['building_class_Residential']\n",
    "\n",
    "# sub_commercial = submission[submission['building_class_Commercial'] == 1]\n",
    "# sub_residential = submission[submission['building_class_Residential'] == 1]\n",
    "# del sub_commercial['building_class_Commercial']\n",
    "# del sub_residential['building_class_Residential']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53b8531",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "716e3138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(original, predicted):\n",
    "    \n",
    "    aggregate = 0\n",
    "    \n",
    "    for orig, pred in zip(original, predicted):\n",
    "        aggregate += (orig - pred)**2\n",
    "    \n",
    "    RMSE_ = math.sqrt(1/len(original) * aggregate)\n",
    "        \n",
    "    print(f'RMSE: {RMSE_}')\n",
    "    \n",
    "    return RMSE_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6dd21",
   "metadata": {},
   "source": [
    "## Ensemble model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0876fc",
   "metadata": {},
   "source": [
    "#### Divide per building_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4df1aeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model per state_factor\n",
    "# train model per building_type\n",
    "# train catboost per building_type!\n",
    "\n",
    "red_commercial = reduced[reduced['building_class_Commercial'] == 1]\n",
    "red_residential = reduced[reduced['building_class_Residential'] == 1]\n",
    "del red_commercial['building_class_Commercial']\n",
    "del red_residential['building_class_Residential']\n",
    "\n",
    "sub_commercial = submission[submission['building_class_Commercial'] == 1]\n",
    "sub_residential = submission[submission['building_class_Residential'] == 1]\n",
    "del sub_commercial['building_class_Commercial']\n",
    "del sub_residential['building_class_Residential']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b18a25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# red_residential.groupby(\"State_Factor\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d0bf58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_commercial.groupby(\"State_Factor\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b7cd698",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_red = [red_commercial, red_residential]\n",
    "models_sub = [sub_commercial, sub_residential]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33ad7db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(model_name):\n",
    "    \n",
    "    X = model_name\n",
    "    ids = X[\"id\"]\n",
    "    X.pop(\"id\")\n",
    "    \n",
    "    return X, ids\n",
    "\n",
    "def get_X_y(model_name):\n",
    "    \n",
    "    X = model_name\n",
    "    y = X['site_eui']\n",
    "    y_id = X['id']\n",
    "    X.pop('site_eui')\n",
    "    X.pop('id')\n",
    "    X.pop('State_Factor_State_6')\n",
    "    \n",
    "    return X, y, y_id\n",
    "\n",
    "def runmodel_predict(X, y, testdata, model):\n",
    "    model.fit(X, y)\n",
    "    preds = model.predict(testdata)\n",
    "    return preds\n",
    "\n",
    "def run_types_pred(data_train, data_test):\n",
    "    \n",
    "    ids = []\n",
    "    resultlist_xgb = []\n",
    "    resultlist_lgbm = []\n",
    "    \n",
    "    for train, test in zip(data_train, data_test):\n",
    "        \n",
    "        # XGBoost\n",
    "    \n",
    "        print(\"XGBoost\")\n",
    "        X, y, y_idx = get_X_y(train)\n",
    "        testdata, y_id = get_pred(test)\n",
    "        ids.append(y_id)\n",
    "        \n",
    "        data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "        model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 11, alpha = 0.2, n_estimators = 1000)\n",
    "        \n",
    "        predicted = runmodel_predict(X, y, testdata, model)\n",
    "        resultlist_xgb.append(predicted)\n",
    "        \n",
    "        # LightGBM\n",
    "        \n",
    "        print(\"LightGBM\")\n",
    "        model = lgbm.LGBMRegressor(max_depth=10, learning_rate=0.2, n_estimators=2400)\n",
    "        predicted = runmodel_predict(X, y, testdata, model)\n",
    "        resultlist_lgbm.append(predicted)\n",
    "        \n",
    "    return resultlist_xgb, resultlist_lgbm, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "551a9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "LightGBM\n",
      "XGBoost\n",
      "LightGBM\n"
     ]
    }
   ],
   "source": [
    "to_concat_xgb_t, to_concat_lgbm_t, ids = run_types_pred(models_red, models_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5bf86bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids2 = [i for si in ids for i in si]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6d536b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids2 heeft id's\n",
    "ids2 = [i for si in ids for i in si]\n",
    "xgb = []\n",
    "lgbm = []\n",
    "cb = []\n",
    "\n",
    "for i in to_concat_xgb_t:\n",
    "    xgb.append(i)\n",
    "    \n",
    "for i in to_concat_lgbm_t:\n",
    "    lgbm.append(i)\n",
    "    \n",
    "for i in catbooster:\n",
    "    cb.append(i)\n",
    "\n",
    "xgb = [item for sublist in xgb for item in sublist]\n",
    "lgbm = [item for sublist in lgbm for item in sublist]\n",
    "cb = [item for sublist in cb for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8d0fc55c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9705, 9705, 9705)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xgb), len(lgbm), len(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0756af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_predicted = []\n",
    "\n",
    "for i, j in zip(xgb, lgbm):\n",
    "    avg_predicted.append((i+j)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac3fc0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[220.36429, 274.92633, 218.76958, 261.40292, 246.63524]\n",
      "[203.3668235484881, 225.11405530038988, 142.16586179739295, 240.01912258114322, 184.61675566156586]\n",
      "[211.86555593928313, 250.02019293339805, 180.46771941188007, 250.7110230825638, 215.6259971545134]\n",
      "[75757, 75758, 75759, 75760, 75761]\n"
     ]
    }
   ],
   "source": [
    "print(xgb[:5])\n",
    "print(lgbm[:5])\n",
    "print(avg_predicted[:5])\n",
    "print(ids2[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49530bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame()\n",
    "result[\"id\"] = ids2\n",
    "result[\"site_eui\"] = avg_predicted\n",
    "result = result.sort_values(by=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9c76257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV file\n",
    "\n",
    "result.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/xgb_lgbm6.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d8a5e50b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e56a245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runmodel_train(X, y, model):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=22)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "    print(\"RMSE: %f\" % (rmse))\n",
    "    return preds, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e990e9d",
   "metadata": {},
   "source": [
    "### XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e27ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [number - 1 for number in numbers]\n",
    "def run_types_train(datasets):\n",
    "    \n",
    "    resultlist_xgb = []\n",
    "    resultlist_lgbm = []\n",
    "    \n",
    "    for i, m in enumerate(datasets):\n",
    "        \n",
    "        # XGBoost\n",
    "        \n",
    "        print(f\"Iteration {i}\")\n",
    "        print(\"XGBoost\")\n",
    "        X, y, y_id = get_X_y(m)\n",
    "        \n",
    "        data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "        model = xgb.XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.2,\n",
    "                max_depth = 11, alpha = 0.2, n_estimators = 1000)\n",
    "        \n",
    "        predicted, original = runmodel_train(X, y, model)\n",
    "        resultlist_xgb.append((list(predicted), list(original)))\n",
    "        \n",
    "        # LightGBM\n",
    "        \n",
    "        print(\"LightGBM\")\n",
    "        model = lgbm.LGBMRegressor(max_depth=10, learning_rate=0.2, n_estimators=2400)\n",
    "        predicted, original = runmodel_train(X, y, model)\n",
    "        resultlist_lgbm.append((list(predicted), list(original)))\n",
    "        \n",
    "    return resultlist_xgb, resultlist_lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ac6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_concat_xgb, to_concat_lgbm = run_types(models_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc5fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds2 = []\n",
    "\n",
    "predicted = []\n",
    "original = []\n",
    "\n",
    "for i in to_concat_xgb:\n",
    "    predicted.append(i[0])\n",
    "    original.append(i[1])\n",
    "\n",
    "predicted = [item for sublist in predicted for item in sublist]\n",
    "\n",
    "preds2.append(predicted)\n",
    "\n",
    "predl = []\n",
    "for i in to_concat_lgbm:\n",
    "    predl.append(i[0])\n",
    "\n",
    "predl = [item for sublist in predl for item in sublist]\n",
    "preds2.append(predl)\n",
    "\n",
    "original = [item for sublist in original for item in sublist]\n",
    "\n",
    "RMSE(original, predicted)\n",
    "RMSE(original, predl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3aa7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take avg of different model values\n",
    "# expm1(mean(log1p(x)))\n",
    "\n",
    "avg_predicted = []\n",
    "\n",
    "for i, j in zip(preds2[0], preds2[1]):\n",
    "    print(np.exp(np.log((i+j)/2)))\n",
    "#     avg_predicted.append((3*i+j)/4)\n",
    "\n",
    "RMSE(original, avg_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc01981",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124af072",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d099660",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52dcd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgbm.LGBMRegressor(max_depth=10, learning_rate=0.2, n_estimators=2400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467c6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe985b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 37.48368551936998\n",
    "\n",
    "predicted = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dff9edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSE(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766bf453",
   "metadata": {},
   "source": [
    "### Catboost (Does not work on Apple M1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a983bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_MAX_DEPTH = 12\n",
    "MODEL_TASK_TYPE = 'GPU'\n",
    "MODEL_RL = 0.025\n",
    "MODEL_EVAL_METRIC ='RMSE'\n",
    "MODEL_LOSS_FUNCTION = 'RMSE'\n",
    "MODEL_ESR = 10\n",
    "MODEL_VERBOSE = 1000\n",
    "MODEL_ITERATIONS = 28000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebb881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CatBoostRegressor(\n",
    "    verbose=1000,\n",
    "    early_stopping_rounds=10,\n",
    "    #random_state=41,\n",
    "    random_seed=535,\n",
    "    max_depth=MODEL_MAX_DEPTH,\n",
    "    task_type=MODEL_TASK_TYPE,\n",
    "    learning_rate=MODEL_RL,\n",
    "    iterations=28000\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e64858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest score RMSE: 38.672019\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "print(\"RMSE: %f\" % (rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60b21b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbf62b1",
   "metadata": {},
   "source": [
    "#### Fit testset, write to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8015afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now fit on whole training set\n",
    "model.fit(X, y)\n",
    "predicted = model.predict(submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddf43fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Preds to DataFrame \n",
    "\n",
    "result = pd.DataFrame(Y_test_sub)\n",
    "result[\"site_eui\"] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9140a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV file\n",
    "\n",
    "result.to_csv('/Users/charlottefelius/documents/WIDS2022/WIDS/results/attempt32.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721413bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wids",
   "language": "python",
   "name": "wids"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
